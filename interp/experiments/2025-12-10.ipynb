{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f47eb3",
   "metadata": {},
   "source": [
    "This experiment uses the Moore-Penrose Pseudoinverse to identify and erase a specific concept (Verb Tense) from the model's internal representation.\n",
    "\n",
    "This is a Linear Probe technique. We assume the model represents \"Past Tense\" as a specific direction vector ($v$) in its high-dimensional space. If we find that vector and flatten it (project it to zero), the model should lose the ability to understand or generate past tense.\n",
    "\n",
    "The Experiment: \"The Tense Lobotomy\"\n",
    "\n",
    "We will:\n",
    "1. Harvest Activations: Run the model on \"Past\" vs. \"Present\" sentences and save the hidden states.\n",
    "2. Compute the Direction: Use the Pseudoinverse to find the linear direction that best separates these two groups.\n",
    "3. Create the Eraser: Build a projection matrix ($P$) that removes only that direction.\n",
    "4. Intervene: Implant this matrix into the model and verify if it \"forgets\" the concept of the past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c61669",
   "metadata": {},
   "source": [
    "## Step 1: Data Setup & Harvesting\n",
    "\n",
    "First, we collect the activations of the model when it sees past vs present tense verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49370472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from nnsight import LanguageModel\n",
    "                            \n",
    "model = LanguageModel(\"openai-community/gpt2\")\n",
    "model.to_device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5375934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 768])\n"
     ]
    }
   ],
   "source": [
    "past_sentences = [\n",
    "    \"I walked to the store\", \"She ran fast\", \"They ate takeout\",\n",
    "    \"He studied hard\", \"We played soccer\", \"It rained heavily\",\n",
    "]\n",
    "present_sentences = [\n",
    "    \"I walk to the store\", \"She runs fast\", \"They eat takeout\",\n",
    "    \"He studies hard\", \"We play soccer\", \"It rains heavily\"\n",
    "]\n",
    "\n",
    "all_prompts = past_sentences + present_sentences\n",
    "n_past = len(past_sentences)\n",
    "n_present = len(present_sentences)\n",
    "\n",
    "target_layer = 6\n",
    "acts_storage = []\n",
    "\n",
    "with torch.no_grad(), model.trace(all_prompts):\n",
    "    # Get just the last token hidden states.\n",
    "    hidden_states = model.transformer.h[target_layer].output[0][:, -1, :].save()\n",
    "\n",
    "activations = hidden_states\n",
    "print(activations.shape) # (12 x 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd18f5",
   "metadata": {},
   "source": [
    "## Step 2: Finding the \"Tense Direction\"\n",
    "\n",
    "We want a vector $w$ such that $Activations \\cdot w \\approx Labels$. Because our activation matrix ($A$) is not square, we cannot invert it. We use the Pseudoinverse ($A^+$) to solve for w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3bc2636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "# 1. Create labels (+1 for Past, -1 for Present)\n",
    "# We cast to the same device/dtype as activations\n",
    "labels = torch.cat([\n",
    "    torch.ones(n_past),\n",
    "    torch.ones(n_present) * -1\n",
    "]).to(activations.device).to(activations.dtype)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27ebea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo Inverse Shape: torch.Size([768, 12])\n",
      "Tense Direction Shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# 2. Compute the \"Concept Direction\" vector (w)\n",
    "# This is the Linear Probe\n",
    "# w = pinv(A) @ Y\n",
    "# A is our collected activations.\n",
    "pseudo_inverse = torch.linalg.pinv(activations)\n",
    "print(\"Pseudo Inverse Shape:\", pseudo_inverse.shape) # (768 x 12)\n",
    "\n",
    "# w = pinv(A) @ Y\n",
    "tense_direction = torch.matmul(pseudo_inverse, labels)\n",
    "print(\"Tense Direction Shape:\", tense_direction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a1f515ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Shape: torch.Size([768, 1])\n",
      "P Shape: torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "# 3. Construct the \"Eraser\" (Projection Matrix)\n",
    "# We want to keep everything orthogonal to the tense direction.\n",
    "# P = I - (v v^T) / (v^T v)\n",
    "v = tense_direction.unsqueeze(1) # Make it a column vector\n",
    "print(\"v Shape:\", v.shape) # (768 x 1)\n",
    "\n",
    "P = torch.eye(v.shape[0], device=v.device) - (v @ v.T) / (v.T @ v)\n",
    "print(\"P Shape:\", P.shape) # (768 x 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ff5a7",
   "metadata": {},
   "source": [
    "## Steo 3: The Intervention\n",
    "\n",
    "Now we verify if the surgery works. We feed the model a prompt that requires past tense completion and force the activation through our Eraser matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76dcd7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT:\n",
      "Prompt: 'Yesterday, I' --> Generated: '<|endoftext|><|endoftext|>Yesterday, I'm going to be doing'\n",
      "Prompt: 'In the past, she' --> Generated: 'In the past, she has been a vocal critic'\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"Yesterday, I\",\n",
    "    \"In the past, she\"\n",
    "]\n",
    "\n",
    "# CORRUPTED RUN\n",
    "with model.generate(test_prompts, max_new_tokens=5, do_sample=False):\n",
    "    \n",
    "    # Access the exact same layer we trained on\n",
    "    current_hidden = model.transformer.h[target_layer].output[0]\n",
    "    \n",
    "    # The intervention\n",
    "    # Apply the projection matrix P to the hidden states.\n",
    "    # This removes the \"Past Tense\" component from the vector.\n",
    "    # We transpose P because torch matmul expects (Batch, Dim) @ (Dim, Dim)\n",
    "    # Note: We apply this to ALL tokens in the sequence\n",
    "    \n",
    "    # We cast P to the correct dtype (usually float16/bfloat16 on GPU)\n",
    "    P = P.to(current_hidden.device).to(current_hidden.dtype)\n",
    "    \n",
    "    # Intervention: x_new = x @ P\n",
    "    # We update the hidden state in-place\n",
    "    current_hidden[:] = torch.matmul(current_hidden, P)\n",
    "    \n",
    "    # Save the output to see what the model generates\n",
    "    output = model.generator.output.save()\n",
    "    \n",
    "# Decode the result\n",
    "print(\"RESULT:\")\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    completion = model.tokenizer.decode(output[i])\n",
    "    print(f\"Prompt: '{prompt}' --> Generated: '{completion}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e5484b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT:\n",
      "Prompt: 'Yesterday, I' --> Generated: '<|endoftext|><|endoftext|>Yesterday, I was in the middle of'\n",
      "Prompt: 'In the past, she' --> Generated: 'In the past, she has been a vocal critic'\n"
     ]
    }
   ],
   "source": [
    "test_prompts = [\n",
    "    \"Yesterday, I\",\n",
    "    \"In the past, she\"\n",
    "]\n",
    "\n",
    "# CLEAN RUN (For comparison)\n",
    "with model.generate(test_prompts, max_new_tokens=5, do_sample=False):\n",
    "    \n",
    "    # Access the exact same layer we trained on\n",
    "    current_hidden = model.transformer.h[target_layer].output[0]\n",
    "    \n",
    "    # Save the output to see what the model generates\n",
    "    output = model.generator.output.save()\n",
    "    \n",
    "# Decode the result\n",
    "print(\"RESULT:\")\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    completion = model.tokenizer.decode(output[i])\n",
    "    print(f\"Prompt: '{prompt}' --> Generated: '{completion}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02662b08",
   "metadata": {},
   "source": [
    "## Probe Comparison Experiment\n",
    "\n",
    "The `pinv` method is Linear Regression (Ordinary Least Squares). Here is how the family of linear probes compares:\n",
    "\n",
    "1. Linear Regression (OLS / Pseudoinverse): Minimizes the squared error between the projection and the label. Good for regression, sometimes noisy for classification.\n",
    "2. Difference of Means: Simply subtracts the \"Present\" centroid from the \"Past\" centroid. ($\\mu_{past} - \\mu_{present}$). This is extremely robust when you have very little data (like our $N = 12$), but ignores the shape/variance of the data.\n",
    "3. Logistic Regression: Optimizes explicitly for classification accuracy (separating the two classes) using a sigmoid function. This is often considered the \"gold standard\" for probing.\n",
    "4. Support Vector Machines (SVM): Finds the hyperplane that maximizes the margin (distance) between two classes.\n",
    "\n",
    "We will implement a \"Probe Battle\" to see which method produces the most effective \"Concept Erasure\" for our small dataset.\n",
    "\n",
    "**Note:** Since our dataset is tiny ($N = 12$), expect Difference of Means to perform well because it is less prone to overfitting than Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50b9372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Erasure Experiment on Layer 6 ---\n",
      "\n",
      "Method: Diff-of-Means\n",
      "    'Yesterday, I' --> '<|endoftext|><|endoftext|> was in the middle of a'\n",
      "    'In the past, she' --> 'has been accused of being a'\n",
      "\n",
      "Method: Linear Reg (OLS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/opt/miniconda3/envs/retrieval-env/lib/python3.11/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    'Yesterday, I' --> '<|endoftext|><|endoftext|>'m going to be doing a'\n",
      "    'In the past, she' --> 'has been a vocal critic of'\n",
      "\n",
      "Method: Logistic Reg\n",
      "    'Yesterday, I' --> '<|endoftext|><|endoftext|>'m going to be doing a'\n",
      "    'In the past, she' --> 'has been a vocal critic of'\n",
      "\n",
      "Method: SVM\n",
      "    'Yesterday, I' --> '<|endoftext|><|endoftext|>'m going to be doing a'\n",
      "    'In the past, she' --> 'has been a vocal critic of'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Prepare the data for scikit-learn (CPU, Numpy)\n",
    "X = hidden_states.cpu().numpy()\n",
    "# Labels: 1 for Past, 0 for Present (standard for sklearn)\n",
    "y = np.array([1] * n_past + [0] * n_present)\n",
    "\n",
    "# Labels for Linear Regression (1 and -1 often works better for OLS centering)\n",
    "y_ols = np.array([1] * n_past + [-1] * n_present)\n",
    "\n",
    "def get_direction_diff_means(X, y):\n",
    "    # Mean of Past - Mean of Present\n",
    "    mu_past = X[y==1].mean(axis=0)\n",
    "    mu_present = X[y==0].mean(axis=0)\n",
    "    direction = mu_past - mu_present\n",
    "    return torch.tensor(direction, dtype=torch.float32)\n",
    "\n",
    "def get_direction_ols(X, y_signed):\n",
    "    # w = A^+ Y (The method we used before)\n",
    "    # Convert back to torch for simple linalg\n",
    "    A = torch.tensor(X, dtype=torch.float32)\n",
    "    Y = torch.tensor(y_signed, dtype=torch.float32)\n",
    "    return torch.linalg.pinv(A) @ Y\n",
    "\n",
    "def get_direction_logistic(X, y):\n",
    "    # Train Logistic Regression classifier\n",
    "    clf = LogisticRegression(random_state=9001, solver='liblinear', max_iter=1000).fit(X, y)\n",
    "    # The coefficients are the normal vector to the decision boundary\n",
    "    return torch.tensor(clf.coef_[0], dtype=torch.float32)\n",
    "\n",
    "def get_direction_svm(X, y):\n",
    "    # Train Linear SVM\n",
    "    clf = LinearSVC(random_state=9001, dual=\"auto\").fit(X, y)\n",
    "    return torch.tensor(clf.coef_[0], dtype=torch.float32)\n",
    "\n",
    "# The Probe Battle Loop\n",
    "\n",
    "methods = {\n",
    "    \"Diff-of-Means\": lambda: get_direction_diff_means(X, y),\n",
    "    \"Linear Reg (OLS)\": lambda: get_direction_ols(X, y_ols),\n",
    "    \"Logistic Reg\": lambda: get_direction_logistic(X, y),\n",
    "    \"SVM\": lambda: get_direction_svm(X, y)\n",
    "}\n",
    "\n",
    "print(f\"--- Running Erasure Experiment on Layer {target_layer} ---\")\n",
    "\n",
    "for name, method_fn in methods.items():\n",
    "    print(f\"\\nMethod: {name}\")\n",
    "    \n",
    "    # 1. Calculate Direction\n",
    "    direction = method_fn().to(model.device)\n",
    "    \n",
    "    # 2. Create Projector (P)\n",
    "    # P = I - vvT / vTv\n",
    "    direction = direction / torch.norm(direction) # Normalize\n",
    "    v = direction.unsqueeze(1)\n",
    "    P = torch.eye(v.shape[0], device=v.device) - (v @ v.T)\n",
    "    \n",
    "    # 3. Intervene and Generate\n",
    "    with model.generate(test_prompts, max_new_tokens=6, do_sample=False):\n",
    "        # Hook the target layer\n",
    "        current_hidden = model.transformer.h[target_layer].output[0]\n",
    "        \n",
    "        # Apply projection to all tokens\n",
    "        # We broadcast P: [Hidden, Hidden] onto [Batch, Seq, Hidden]\n",
    "        current_hidden[:] = torch.matmul(current_hidden, P.to(current_hidden.dtype))\n",
    "        \n",
    "        output = model.generator.output.save()\n",
    "        \n",
    "    # 4. Report\n",
    "    for i, p in enumerate(test_prompts):\n",
    "        gen = model.tokenizer.decode(output[i]).replace(p, \"\").strip()\n",
    "        print(f\"    '{p}' --> '{gen}'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
