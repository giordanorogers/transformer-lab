{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9c300d",
   "metadata": {},
   "source": [
    "Now that we know how to access the parameters, let's look at how to initialize them properly.\n",
    "\n",
    "The deep learning framwork provides default random initialization to its layers. However, we often want to initalize our weights according to various other protocols. The framework provides most commonly used protocols, and also allows us to create a custom initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef8c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8c3a1",
   "metadata": {},
   "source": [
    "By default, PyTorch initializes weight and bias matrices uniformly by drawing from a range that is computed according to the input and output dimension. PyTorch's nn.init module provides a variety of preset initialization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b2c5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/d2l/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(), nn.LazyLinear(1))\n",
    "X = torch.rand(size=(2,4))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735de4e",
   "metadata": {},
   "source": [
    "Let's begin by calling on built-in initializers. The code below initializes all weight parameters as Gaussian random variables with standard deviation 0.01, while bias parameters are cleared to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e338e646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0509,  0.0014,  0.0188,  0.0171]), tensor(0.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.normal_(module.weight, mean=0, std=0.1)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ce837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
